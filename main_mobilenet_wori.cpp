//** Object Detection streaming version â€“ with GPU


#include <vector>
#include <memory>
#include <string>
#include <iostream>
#include <opencv2/opencv.hpp>
#include <inference_engine.hpp>

#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <termios.h>
#include <unistd.h>
#include <fcntl.h>

#include <X11/Xlib.h>
const char *labels[20] = {"plane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "table",
			"dog", "horse", "motorcycle", "person", "plant", "sheep", "sofa", "train", "monitor"};

using namespace std;
using namespace cv;
using namespace InferenceEngine;
//modify
int kbhit(void)
{
  struct termios oldt, newt;
  int ch;
  int oldf;
  tcgetattr(STDIN_FILENO, &oldt);
  newt = oldt;
  newt.c_lflag &= ~(ICANON | ECHO);
  tcsetattr(STDIN_FILENO, TCSANOW, &newt);
  oldf = fcntl(STDIN_FILENO, F_GETFL, 0);
  fcntl(STDIN_FILENO, F_SETFL, oldf | O_NONBLOCK);
  ch = getchar();
  tcsetattr(STDIN_FILENO, TCSANOW, &oldt);
  fcntl(STDIN_FILENO, F_SETFL, oldf);
  if(ch != EOF)
  {
    //DO whatever you like to do with this charecter ..
    ungetc(ch, stdin);
    return 1;
  }
  return 0;
}

int main(int argc, char *argv[]) {

	//screen size
	Display* disp = XOpenDisplay(NULL);
	Screen*  scrn = DefaultScreenOfDisplay(disp);
	int height = scrn->height;
	int width  = scrn->width;
	/*int width = GetSystemMetrics(SM_CXSCREEN);
	int height = GetSystemMetrics(SM_CYSCREEN);*/

	

	// ---------------------Load A Plugin for Inference Engine-

	InferenceEngine::PluginDispatcher dispatcher({""});
	InferencePlugin plugin(dispatcher.getSuitablePlugin(TargetDevice::eGPU));


	// --------------------Load IR Generated by ModelOptimizer (.xml and .bin files)------------------------

	CNNNetReader network_reader;
	
	network_reader.ReadNetwork("/home/intel/my_model/FP16/mobilenet-ssd.xml");
	network_reader.ReadWeights("/home/intel/my_model/FP16/mobilenet-ssd.bin");
	network_reader.getNetwork().setBatchSize(1);

	CNNNetwork network = network_reader.getNetwork();

	// -----------------------------Prepare input blobs-----------------------------------------------------

	auto input_info = network.getInputsInfo().begin()->second;
	auto input_name = network.getInputsInfo().begin()->first;

	input_info->setPrecision(Precision::U8);

	// ---------------------------Prepare output blobs------------------------------------------------------

	auto output_info = network.getOutputsInfo().begin()->second;
	auto output_name = network.getOutputsInfo().begin()->first;
	
	output_info->setPrecision(Precision::FP32);

	// -------------------------Loading model to the plugin and then infer----------------------------------

	auto executable_network = plugin.LoadNetwork(network, {});
	auto infer_request = executable_network.CreateInferRequest();

	auto input = infer_request.GetBlob(input_name);
	auto input_data = input->buffer().as<PrecisionTrait<Precision::U8>::value_type*>();

	char buf[256];
	VideoCapture cap("final.mp4");//<-- usb camera or can be any video stream
	Mat warning=imread("warning.png");
	Mat alarming=imread("complete.jpg");
	Mat frame;

	bool bret;

	if(!cap.isOpened())
	{
		cout << "can't open input device" << endl;
		return 1;
	}

	Mat ori_image, infer_image;
	//-------mail modify-------
	bret = cap.read(ori_image);	

	if(bret == false)
		return 1;

	int flag = 0;
	int i=0;
	while(1)
	{	
		
		// read one frame from input stream
		cap.read(ori_image);
		
		resize(ori_image, infer_image, Size(input_info->getDims()[0], input_info->getDims()[1]));
		
		namedWindow("result",WINDOW_NORMAL);
		resizeWindow("result",width/2,(height*3/4-40));
		moveWindow("result", width/2, 0);
		namedWindow("result2",WINDOW_NORMAL);
		resizeWindow("result2",width/2,height/4);
		moveWindow("result2", width/2, (height*3/4));
		//namedWindow("result2",WINDOW_NORMAL);
		//resizeWindow("result2",1050,500);
		//moveWindow("result2", 1000, 600);
		//namedWindow("infer", WINDOW_NORMAL);
		//resizeWindow("infer", 600,600);
		//imshow("infer", infer_image);
		//waitKey(0);

		size_t channels_number = input->dims()[2];
		size_t image_size = input->dims()[1] * input->dims()[0];


		for(size_t pid = 0; pid < image_size; ++pid) {
			for(size_t ch = 0; ch < channels_number; ++ch)	{
				input_data[ch*image_size+pid] = infer_image.at<Vec3b>(pid)[ch];
			}
		}

		/* Running the request synchronously */
		infer_request.Infer();

		// ---------------------------Postprocess output blobs--------------------------------------------------

		auto output = infer_request.GetBlob(output_name);

		// +++++++++++++ check proposal count and objectsize of each proposal +++++++++++
		const int maxProposalCount = output->dims()[1];
		const int objectSize = output->dims()[0];

		const Blob::Ptr output_blob = output;
		const float* detection = static_cast<PrecisionTrait<Precision::FP32>::value_type*>(output_blob->buffer());

		/* Each detection has image_id that denotes processed image */
		for (int curProposal = 0; curProposal < maxProposalCount; curProposal++) {
			float image_id = detection[curProposal * objectSize + 0];
			float label_index = detection[curProposal * objectSize + 1];
			float confidence = detection[curProposal * objectSize + 2];
			/* CPU and GPU plugins have difference in DetectionOutput layer, so we need both checks */
			if (image_id < 0 || confidence == 0) {
				continue;
			}

			float xmin = detection[curProposal * objectSize + 3] * ori_image.size().width;
			float ymin = detection[curProposal * objectSize + 4] * ori_image.size().height;
			float xmax = detection[curProposal * objectSize + 5] * ori_image.size().width;
			float ymax = detection[curProposal * objectSize + 6] * ori_image.size().height;

			//cout << "[" << curProposal << "," << label_index << "] element, prob = " << confidence << "    (" << xmin << "," << ymin << ")-(" << xmax << "," << ymax << ")" << " batch id : " << image_id;
			if(kbhit())
					{
						//clearing the buffer
						char ch = getchar();
						//cout<<"get key\n";
						if(ch=='p')
						{
							i=0;
							printf("\ninitialize detection\n");
							imshow("result2", alarming);
							waitKey(1000);
							destroyWindow("result2");

						}
					}
			if (confidence > 0.5) {
			/** Drawing only objects with >50% probability **/
				string stag;
				ostringstream ostr;                        
				ostr << labels[(int)label_index - 1] << ", " << fixed << setw(4) << setprecision(2) << confidence;
				string header = ostr.str();
				
				//cout << " WILL BE PRINTED!";
				if (labels[(int)label_index - 1]=="person"){
					cout<<"Person\n";
					cap >> frame;
					imwrite("capture1.jpg",frame);					
					
					
					//imshow("result2",alarming);
					for(i; i<8; i++)
					{	
						frame=warning;	
						imshow("result",frame);	
						system("canberra-gtk-play -f beep.wav");							
						waitKey(400);
						frame = imread("capture1.jpg");
						imshow("result",frame);						
						waitKey(400);	
						
					}
					
				
				}
				else{
					rectangle(ori_image, Point((int)xmin, (int)ymin), Point((int)xmax, (int)ymax), Scalar(0, 230, 0), 2, 4);
                                rectangle(ori_image, Point((int)xmin-1, (int)ymin-16), Point((int)xmax+1, (int)ymin), Scalar(0, 230, 0), CV_FILLED, LINE_8, 0);
                                putText(ori_image, header, Point((int)xmin+4, (int)ymin), FONT_HERSHEY_TRIPLEX, .5, Scalar(70,70,70));
                                putText(ori_image, header, Point((int)xmin+3, (int)ymin-1), FONT_HERSHEY_TRIPLEX, .5, Scalar(0,0,0));
				
				}
				
			}  		
			
			//cout << endl;
						
		}
		
		imshow("result", ori_image);
		
						
		
		if (waitKey(1) >= 13)	// enterkey
			break;
	
	}
	return 0;
}
